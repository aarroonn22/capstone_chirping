{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a workbook of my capstone project at Digital Futures. The aim was to create an algorithm that will be able to identify birds based on their chirping. A dataset from xeno-canto.org via kaggle was used. For reasons of simplicity and versatility, the algorithm only uses audio data as input when making predictions. Further improvement is desired. You can read about these and a more detailed walk-through of creating the algorithm at https://aarroonn.medium.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy.signal import butter, lfilter\n",
    "from itertools import compress\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS:\n",
    "\n",
    "# BANDPASS FILTER FUNCTION:\n",
    "\n",
    "def bandpass_00(audio, sample_rate, lowcut = 800, highcut = 7000, order = 5):\n",
    "    \n",
    "    '''Creates a bandpass filter for audio signals.\n",
    "    \n",
    "    parameters:\n",
    "    - audio: np.array of signal values\n",
    "    - lowcut: numeric value of lowcut frequency\n",
    "    - highcut: numeric value of highcut frequency\n",
    "    - sample_rate: integer sample rate of audio\n",
    "    - order: numeric order of the filter\n",
    "    \n",
    "    output:\n",
    "    np.array of filtered signal values'''\n",
    "    \n",
    "    nyq = sample_rate * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(N = order, Wn = [low, high], btype = 'bandpass')\n",
    "    output = lfilter(b, a, audio)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# NOISE FILTER FUNCTION:\n",
    "\n",
    "def denoiser_00(audio, sample_rate, aggregate = np.median, metric = 'cosine', window = 1, margin_bg = 10,\n",
    "                margin_front = 10, power = 2):\n",
    "    \n",
    "    '''Function to separate front elements and background noise using spectrogram transformation, filtering\n",
    "    nearest-neighbours and soft-mask operation.\n",
    "    The function is based on one of the 'Advanced examples' from the librosa package documentation:\n",
    "    https://librosa.org/doc/latest/auto_examples/plot_vocal_separation.html#sphx-glr-auto-examples-plot-vocal-separation-py\n",
    "    \n",
    "    parameters:\n",
    "    - audio: np.array of signal values\n",
    "    - sample_rate: integer sample rate of audio\n",
    "    - aggregate: numpy aggregate (per-frequency) function treating the nearest neighbours of each spectrogram input column\n",
    "    - metric: str distance metric used for nearest-neighbour calculation. see sklearn.neighbors.DistanceMetric for a list of options\n",
    "    - window: int>=1 defining in seconds which points to consider neighbour\n",
    "    - margin_bg: numeric>=0 determines the signal strength of the front element in the soft-mask operaion\n",
    "    - margin_front: numeric>=0 determines the signal strength of the background element in the soft-mask operaion\n",
    "    - power: numeric>0 or np.inf the power element of the soft-mask computation\n",
    "    \n",
    "    output:\n",
    "    np.array-s of the filtered front audio and the background audio'''\n",
    "    \n",
    "    # getting spectrogram component and phase of Fourier-transforms of the original audio\n",
    "    ft_mag, ft_phase = librosa.magphase(librosa.stft(audio))\n",
    "    \n",
    "    # returns a combined array of element-wise minimums of the original audio and our neighbours cosine simiarity\n",
    "    # filtered array, so that out filter values will never exceed the original ones\n",
    "    ft_filter = np.minimum(ft_mag,\n",
    "                           librosa.decompose.nn_filter(ft_mag,\n",
    "                                                       aggregate = aggregate,\n",
    "                                                       metric = metric,\n",
    "                                                       width = int(librosa.time_to_frames(window, sr = sample_rate))))\n",
    "    \n",
    "    # getting mask operations for background and front elements. the results will be our local 'magnitudes' to\n",
    "    # separate out elements already present in the original audio. 'ft_filter' is our background elements. we retain\n",
    "    # the front audio by subtracting it from the original audio. note the symmetry between the two masks. that is\n",
    "    # because the two audios serve as 'reference' to each other's masks\n",
    "    \n",
    "    # to save processing time, i comment out the background elements here\n",
    "    #mask_bg = librosa.util.softmask(ft_filter,\n",
    "    #                                margin_bg * (ft_mag - ft_filter),\n",
    "    #                                power = power)\n",
    "    mask_front = librosa.util.softmask(ft_mag - ft_filter,\n",
    "                                       margin_front * ft_filter,\n",
    "                                       power = power)\n",
    "    \n",
    "    # retaining the front and background audio signals\n",
    "    \n",
    "    # to save processing time, i comment out the background elements here\n",
    "    front = mask_front * ft_mag\n",
    "    #bg = mask_bg * ft_mag\n",
    "    audio_front = librosa.istft(front * ft_phase)\n",
    "    #audio_bg = librosa.istft(bg * ft_phase)\n",
    "    \n",
    "    return audio_front#, audio_bg\n",
    "\n",
    "\n",
    "# TIME SAMPLING FUNCTION:\n",
    "\n",
    "def look_pass(list01):\n",
    "    \n",
    "    '''Custom function taking in a boolean list. It was used to find points where our signal just passed a\n",
    "    threshold value.'''\n",
    "    \n",
    "    list00 = []\n",
    "    \n",
    "    for i in range(len(list01) - 1):\n",
    "        if (list01[i], list01[i + 1]) == (False, True):\n",
    "            list00.append(i + 1)\n",
    "            \n",
    "    return list00\n",
    "\n",
    "\n",
    "def tsampler_01(audio, sample_rate, sample_length = 0.5, look_ahead = 0.05, threshold = -15.):\n",
    "    \n",
    "    '''Function to create a sample of given length, from around the first relevant signal strength of audio.\n",
    "    \n",
    "    parameters:\n",
    "    - audio: np.array of signal values\n",
    "    - sample_rate: int sample rate of audio\n",
    "    - sample_length: numeric>0 length of desired sample output(s) in seconds\n",
    "    - look_ahead: numeric>0 length of how many seconds before reaching the threshold should be included in the final sample\n",
    "    - threshold: numeric value of threshold point in dB. only signals exceeding will be sampled\n",
    "    \n",
    "    output:\n",
    "    - a list of np.arrays of audio signals'''\n",
    "    \n",
    "    # for a more stable evaluation of local amplitude of the signal its converted to rms\n",
    "    rms = librosa.feature.rms(y = audio)[0]\n",
    "    \n",
    "    # calculating time arrays for the original and rms signals\n",
    "    t01 = librosa.frames_to_time(np.arange(len(audio)), hop_length = 1, sr = sample_rate)\n",
    "    t02 = librosa.frames_to_time(np.arange(len(rms)), sr = sample_rate)\n",
    "    \n",
    "    # creating a boolean mask, to let through values above our threshold using our function from before\n",
    "    rms_bool = np.where(librosa.amplitude_to_db(rms, ref = np.max) >= threshold, True, False)\n",
    "    t02 = [t02[x] for x in look_pass(rms_bool)]\n",
    "    \n",
    "    # using our sample length, we cut the original audio to sample size. we also return the cutoff points (t_val)\n",
    "    t_bool = [np.where((t01 > x - look_ahead), True, False) for x in t02]\n",
    "    t_val = [round(x - look_ahead, 2) for x in t02]\n",
    "    samples = [np.array(list(compress(audio, x)))[: int(sample_rate * sample_length) + 1] for x in t_bool]\n",
    "    \n",
    "    return samples, t_val\n",
    "\n",
    "\n",
    "# ALL TOGETHER:\n",
    "\n",
    "def audio_treatment(audio, sample_rate = 16000, track = False, track_v = 0, gen = None):\n",
    "    \n",
    "    '''Function to combine the audio manipulating sub-functions.\n",
    "    \n",
    "    parameters:\n",
    "    - audio: np.array of signal values\n",
    "    - sample_rate: int sample rate of audio\n",
    "    - track: boolean value of whether the progress should be tracked\n",
    "    - track_v: int value of the last element to be processed\n",
    "    - gen: a generator object providing value steps\n",
    "    \n",
    "    output:\n",
    "    np.array of processed audio signal'''\n",
    "    \n",
    "    a_t = bandpass_00(audio = audio, sample_rate = sample_rate)\n",
    "    a_t = denoiser_00(audio = a_t, sample_rate = sample_rate)\n",
    "    a_t, t_v = tsampler_01(audio = a_t, sample_rate = sample_rate)\n",
    "    f_t = [np.abs(librosa.stft(x)) for x in a_t]\n",
    "    if track == True:\n",
    "        print(f'{next(gen)} / {track_v} finished')\n",
    "        \n",
    "    return f_t, t_v\n",
    "\n",
    "\n",
    "# PREDICTION FUNCTION:\n",
    "\n",
    "def chirping01(audio):\n",
    "    \n",
    "    '''Fucntion identifying birds based on an audio record of their chirping.\n",
    "    \n",
    "    parameters:\n",
    "    - audio: np.array of signal values\n",
    "    \n",
    "    output:\n",
    "    - a print of specific times and associated bird types'''\n",
    "    \n",
    "    aud, time = audio_treatment(audio)\n",
    "    # if the last samples' shape is not suitable for the model, it is discarded\n",
    "    \n",
    "    while aud[-1].shape != aud[0].shape:\n",
    "        aud = aud[: -1]\n",
    "        time = time[: -1]\n",
    "        \n",
    "    # we scale up the strength of the audio signal and reshape it for our model\n",
    "    aud_db = np.array([librosa.amplitude_to_db(x, ref = np.max) for x in aud])\n",
    "    aud_db = np.array([x.reshape(x.shape[0] * x.shape[1], ) for x in aud_db])\n",
    "    \n",
    "    # we perform a PCA on the signal and perform the prediction\n",
    "    aud_pca = pca01.transform(aud_db)\n",
    "    pred = svc02.predict_proba(aud_pca)\n",
    "    \n",
    "    # we create. asorted list of tuples (bird name, probability)\n",
    "    list_prob = []\n",
    "     \n",
    "    for i in pred:\n",
    "        list_p = []\n",
    "        for j in range(len(i)):\n",
    "            list_p.append((dict_ebird[dict_bird[j]], round(i[j] * 100, 2)))\n",
    "        list_prob.append(list_p)\n",
    "\n",
    "    list_prob.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    # if probabilities exceed 40%, we only print those birds. otherwise, we print all the associated types and probabilities\n",
    "    for k in range(len(time)):\n",
    "        print(f'At {time[k]}sec, we think it\\'s:')\n",
    "        if any(x[1] >= 40 for x in list_prob[k]):\n",
    "            for m in list_prob[k]:\n",
    "                if m[1] >= 40:\n",
    "                    print(f'{m[0]} with {m[1]}% chance')\n",
    "        else:\n",
    "            print('Unfortunately, we cannot really say for sure but these are our guesses:')\n",
    "            for n in list_prob[k]:\n",
    "                print(f'{n[0]} with {n[1]}% chance')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset:\n",
    "\n",
    "df_00 = pd.read_csv('train.csv')\n",
    "df_00.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary of ebird codes to species names, so later we can match these back:\n",
    "\n",
    "dict_ebird = {}\n",
    "for i in df_00.ebird_code.unique():\n",
    "    dict_ebird[i] = df_00[df_00.ebird_code == i].species.unique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the aim is to work only with audio data, only the necessary columns are kept:\n",
    "\n",
    "df_01 = df_00[['rating', 'ebird_code', 'duration', 'filename', 'sampling_rate', 'type']].copy()\n",
    "df_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we haven't null values\n",
    "\n",
    "df_01.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the type of record have more than 1,200 unique values. we want to categorise these into much fewer groups:\n",
    "\n",
    "df_01.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of capitalisation:\n",
    "\n",
    "df_01.type = [x.lower() for x in df_01.type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting out the many different inputs of chirp types into 3 major groups – song, call and miscellaneous:\n",
    "\n",
    "df_01.type = np.where(['song' in x for x in df_01.type], 'song', df_01.type)\n",
    "df_01.type = np.where(['call' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where(['duet' in x for x in df_01.type], 'song', df_01.type)\n",
    "df_01.type = np.where(['alarm' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where(['zweeoo' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where(['chip' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where(['coo' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where(['whistle' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where(['wisthle' in x for x in df_01.type], 'call', df_01.type)\n",
    "df_01.type = np.where((df_01.type != 'song') & (df_01.type != 'call'), 'misc', df_01.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting sample rates to integer format:\n",
    "\n",
    "df_01.sampling_rate = df_01.sampling_rate.str[0: 5]\n",
    "df_01.sampling_rate = df_01.sampling_rate.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a managable subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading audio in and processing it in python is a lengthy process. To save time, I only used a smaller set of samples to train the model and create the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limiting our data to good quality recordings, under a minute with at least 16kHz sampling rate. this is because we\n",
    "# want to be able to detect 8kHz frequencies, so by the Nyquist sampling theorem, we need double the sample rate:\n",
    "\n",
    "df_02 = df_01[(df_01.rating >= 3) & (df_01.duration < 61) & (df_01.sampling_rate >= 16000) &\n",
    "              (df_01.type == 'song')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the most populated datasets, summing around 300 samples:\n",
    "\n",
    "df_02.groupby('ebird_code').ebird_code.count().sort_values(ascending = False)[: 5].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of bird types for our restricted sample:\n",
    "\n",
    "list_ebird = df_02.groupby('ebird_code').ebird_code.count().sort_values(ascending = False)[: 5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining the desired birds:\n",
    "\n",
    "df_02 = df_02[([x in list_ebird for x in df_02.ebird_code])].copy()\n",
    "df_02.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinking ahead, we create two dictionaries that can be used to provide numeric values for our model and translate it\n",
    "# back:\n",
    "\n",
    "bird_dict = {}\n",
    "for i in range(len(df_02.ebird_code.unique())):\n",
    "    bird_dict[df_02.ebird_code.unique()[i]] = i\n",
    "    \n",
    "dict_bird = {}\n",
    "for i in range(len(df_02.ebird_code.unique())):\n",
    "    dict_bird[i] = df_02.ebird_code.unique()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in audio data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a file path from where we can read the audio in:\n",
    "\n",
    "df_02['path'] = ['train_audio/' + df_02.ebird_code[x] + '/' + df_02.filename[x] for x in range(len(df_02))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in audio files. librosa creates an array of amplituda values. this takes some time:\n",
    "\n",
    "df_02['samp'] = df_02.path.apply(lambda x: librosa.load(x, mono = True, sr = 16000, res_type = 'fft')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to track progress, an infinite number generator object was set up:\n",
    "\n",
    "def inf_seq():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "        \n",
    "gen = inf_seq()\n",
    "\n",
    "df_02['audio_tr'] = df_02.samp.apply(lambda x: audio_treatment(x, track = True, track_v = df_02.shape[0],\n",
    "                                                               gen = gen)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retaining and formatting meain features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a multi-dimensional list of our features to use for the model:\n",
    "\n",
    "\n",
    "ft_list = []\n",
    "for i in range(df_02.shape[0]):\n",
    "    ft_list += ([[df_02.ebird_code[i], x] for x in df_02.audio_tr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dataframe of the features for further manipulation:\n",
    "\n",
    "df_03 = pd.DataFrame(np.array(ft_list), columns = ['ebird_code', 'res_ft'])\n",
    "df_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the length of our res_ft does not match the maximum, it is because the threshold was reached at the end of a\n",
    "# recording, so the sample is too short. we get rid of these for equal feature lengths\n",
    "\n",
    "df_03['len_tr'] = [len(x.ravel()) for x in df_03.res_ft]\n",
    "\n",
    "df_03 = df_03[df_03.len_tr == df_03.len_tr.max()].copy()\n",
    "df_03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using our dictionary from earlier, we create y-values for our model:\n",
    "\n",
    "df_03['value'] = df_03.ebird_code.map(bird_dict)\n",
    "y_01 = df_03.value\n",
    "\n",
    "y_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we scale all features up to the same dB level and create a 2-D array for our X-features:\n",
    "\n",
    "res_db = np.array([librosa.amplitude_to_db(x, ref = np.max) for x in df_03.res_ft])\n",
    "X_01 = np.array([x.reshape(x.shape[0] * x.shape[1], ) for x in res_db])\n",
    "\n",
    "X_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test and training sets:\n",
    "\n",
    "X_trn01, X_tst01, y_trn01, y_tst01 = train_test_split(X_01, y_01, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a baseline, a simple and quick Bayesian model is trained on the data:\n",
    "\n",
    "gnb01 = GaussianNB()\n",
    "gnb01.fit(X_trn01, y_trn01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gnb01 = gnb01.predict(X_tst01)\n",
    "accuracy_score(y_tst01, y_gnb01)\n",
    "# baseline it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the plan is to use a support-vector machine and not spend a lifetime gridsearching, a PCA is carried out:\n",
    "\n",
    "pca = PCA().fit(X_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the graph, 500 components seems like a suitable choice:\n",
    "\n",
    "pca01 = PCA(500)\n",
    "X_pca01 = pca01.fit_transform(X_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn02, X_tst02, y_trn02, y_tst02 = train_test_split(X_pca01, y_01, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set up a support-vector machine and a grid for gridsearch:\n",
    "\n",
    "svc01 = SVC(kernel = 'rbf', class_weight = 'balanced', probability = True)\n",
    "grid01 = {'C' : [1, 5, 10, 25],\n",
    "          'gamma' : [1e-07, 5e-07, 1e-06, 5e-06]}\n",
    "svc_grid01 = GridSearchCV(svc01, grid01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid01.fit(X_trn02, y_trn02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_grid01.best_params_)\n",
    "#'C': 10, 'gamma': 5e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc02 = svc_grid01.best_estimator_\n",
    "y_svc02 = svc02.predict(X_tst02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_tst02, y_svc02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix, to see our results:\n",
    "\n",
    "mat = confusion_matrix(y_tst02, y_svc02)\n",
    "\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "sns.heatmap(mat, square = True, annot = True,\n",
    "            xticklabels = pd.Series(y_tst02.unique()).map(dict_bird).map(dict_ebird),\n",
    "            yticklabels = pd.Series(y_tst02.unique()).map(dict_bird).map(dict_ebird))\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc01 = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rfc01.fit(X_trn01, y_trn01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rfc01 = rfc01.predict(X_tst01)\n",
    "accuracy_score(y_tst01, y_rfc01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing against the PCA data too:\n",
    "\n",
    "rfc02 = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rfc02.fit(X_trn02, y_trn02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rfc02 = rfc02.predict(X_tst02)\n",
    "accuracy_score(y_tst02, y_rfc02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on a few trials, 2 neighbours seemed to be the best choice:\n",
    "\n",
    "knn01 = KNeighborsClassifier(n_neighbors = 2)\n",
    "knn01.fit(X_trn02, y_trn02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn01 = knn01.predict(X_tst02)\n",
    "accuracy_score(y_tst02, y_knn01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see if results can be improved, a soft-voting ensemble of the last three models was tried:\n",
    "\n",
    "vcf01 = VotingClassifier(estimators = [('svc', svc02), ('rf', rfc02), ('knn', knn01)],\n",
    "                         voting = 'soft', weights = [2, 1, 2])\n",
    "vcf01.fit(X_trn02, y_trn02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vcf01 = vcf01.predict(X_tst02)\n",
    "accuracy_score(y_tst02, y_vcf01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian:\n",
    "\n",
    "print(metrics.classification_report(y_gnb01, y_tst01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM:\n",
    "\n",
    "print(metrics.classification_report(y_svc02, y_tst02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest:\n",
    "\n",
    "print(metrics.classification_report(y_rfc02, y_tst02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN:\n",
    "\n",
    "print(metrics.classification_report(y_knn01, y_tst02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting ensemble:\n",
    "\n",
    "print(metrics.classification_report(y_vcf01, y_tst02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the function on audio files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the support-vector machine was the best candidate, it was used for making the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirping01(list(df_02.samp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if our model predicted well:\n",
    "\n",
    "dict_ebird[df_02.ebird_code[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the function against a different input:\n",
    "\n",
    "chirping01(df_02.samp[304])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ebird[df_02.ebird_code[304]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
